# Лекция 41. Celery

![](https://i.kym-cdn.com/entries/icons/original/000/022/857/Screen_Shot_2017-05-01_at_12.53.31_PM.png)

![](https://camo.githubusercontent.com/9d76d83ac90c740e056dfba3015b0010ff15c153f62babb5807a87afdc2d452c/68747470733a2f2f692e696d6775722e636f6d2f655555425161512e6a7067)

## Что надо знать до Celery

### Процессы

`Процесс` — экземпляр программы во время выполнения, независимый объект, которому выделены системные ресурсы (например,
процессорное время и память). Каждый процесс выполняется в отдельном адресном пространстве: один процесс не может
получить доступ к переменным и структурам данных другого. Если процесс хочет получить доступ к чужим ресурсам,
необходимо использовать межпроцессное взаимодействие. Это могут быть конвейеры, файлы, каналы связи между компьютерами и
многое другое.

`Синхронным (synchronous)` называется такое взаимодействие между компонентами, при котором клиент, отослав запрос,
блокируется и может продолжать работу только после получения ответа от сервера. По этой причине такой вид взаимодействия
называют иногда `блокирующим (blocking)`.

В рамках `асинхронного (asynchronous)` или `неблокирующего (non blocking)` взаимодействия клиент после отправки запроса
серверу может продолжать работу, даже если ответ на запрос еще не пришел. Асинхронное взаимодействие позволяет получить
более высокую производительность системы за счет использования времени между отправкой запроса и получением ответа на
него для выполнения других задач. Другое важное преимущество асинхронного взаимодействия — меньшая зависимость клиента
от сервера, возможность продолжать работу, даже если машина, на которой находится сервер, стала недоступной. Это
свойство используется для организации надежной связи между компонентами, даже если и клиент, и сервер не все время
находятся в рабочем состоянии.

![](https://blog.function12.io/content/images/2023/11/----.png)

## Что это вообще такое Celery?

**Celery** – это система для управления очередями задач. Принципиально умеет 2 вещи: брать задачи из очереди и выполнять
задачи по расписанию.

Celery - это распределённая очередь задач, реализованная на языке Python.

Celery - это простая, гибкая и надежная распределенная система для обработки огромного количества сообщений, включая в
себя инструменты, необходимые для поддержки такой системы.

Это очередь задач с упором на обработку в реальном времени, а также с поддержкой планирования задач.

Celery имеет открытый исходный код и находится под лицензией BSD.

Итак, что же умеет Celery:

- Выполнять асинхронно задания
- Выполнять периодические задания (умная замена cron)
- Выполнять отложенные задания
- Распределенное выполнение (может быть запущен на N серверах)
- В пределах одного worker’а возможно конкурентное выполнение нескольких задач (одновременно)
- Выполнять задание повторно, если вылез exception
- Ограничивать количество заданий в единицу времени (rate limit для задания или глобально)
- Несложно мониторить выполнение заданий
- Выполнять подзадания
- Присылать отчеты об exception’ах
- Проверять выполнилось ли задание

![](https://miro.medium.com/v2/resize:fit:1400/1*FRkffS6BCCU36LBHglfF9A.png)


### Task (Задача)

Задачей является предварительно написанный код (чаще всего функция), предназначенный для выполнения определённой цели 
(отправка имейла, обработка файла, и т. д.)

### Broker (Брокер)

Брокер сообщений (он же диспетчер очереди) — это посредник(транспорт), который принимает и отдает сообщения (задачи)
между отдельными модулями/приложениями внутри некоторой сложной системы, где модули/приложения должны общаться между
собой — то есть пересылать данные друг другу.

Брокером может выступать как специальное ПО, например, RabbitMQ, так и некоторые NoSQL, например Redis. О них подробнее
ниже.

### Worker (Воркер)

Воркер - это отдельно запущенный процесс для выполнения определённых задач, Celery запускается на одном или нескольких
воркерах, чтобы выполнять задачи параллельно на каждом воркере.

### Back-end (Бэкэнд)

В рамках Celery бэкэнд выступает в качестве хранилища результатов выполнения задач. Это может быть как SQL, так и NoSQL
база данных. Хотя, по сути что угодно может быть хранилищем, хоть обычный файл (я таких реализаций не встречал, но
технически возможно).

- *Producer (поставщик)* ‒ программа, отправляющая сообщения. В нашем случае, это чаще всего будет Django.

- *Queue (очередь)* ‒ очередь сообщений (задач). Она существует внутри брокера. Любое количество поставщиков может
  отправлять сообщения в одну очередь, также любое количество подписчиков может получать сообщения из одной очереди. В
  схемах очередь будет обозначена стеком и подписана именем. Чаще всего за очередь будет отвечать Redis.

- *Consumer (подписчик)* ‒ программа, принимающая сообщения. Обычно подписчик находится в состоянии ожидания сообщений.
  Это будет процесс Celery, который запустили специально для этой цели. Обрабатывает задачи, и складывает результат в
  backend.

Поставщик, подписчик и брокер не обязаны находиться на одной физической машине.

### Брокеры

![](https://assets-global.website-files.com/5ff66329429d880392f6cba2/619f53ce469a19d18a61ef94_AMQP%20Broker.png)

#### AMQP

*AMQP (Advanced Message Queuing Protocol)* — открытый протокол для передачи сообщений между компонентами системы. 
Основная идея состоит в том, что отдельные подсистемы (или независимые приложения) могут обмениваться произвольным 
образом сообщениями через AMQP-брокер, который осуществляет маршрутизацию, возможно гарантирует доставку, распределение
потоков данных, подписку на нужные типы сообщений.

#### RabbitMQ

`RabbitMQ` – это брокер сообщений с открытым исходным кодом. Он маршрутизирует сообщения по всем базовым принципам
протокола AMQP, описанным в спецификации. Отправитель передает сообщение брокеру, а тот доставляет его получателю.
RabbitMQ реализует и дополняет протокол AMPQ.

#### Redis

`Redis` (Remote Dictionary Server) – это быстрое хранилище данных типа «ключ‑значение» в памяти с
открытым исходным кодом для использования в качестве базы данных, кэша, брокера сообщений или очереди.

Redis это `NoSQL` база данных! Для Celery крайне рекомендую использовать именно его.

![](https://camo.githubusercontent.com/135643e6e08c05b60121fa3deb83b49abc61362f1698dbeee8043e642ac24160/68747470733a2f2f7777772e626f74726565746563686e6f6c6f676965732e636f6d2f626c6f672f77702d636f6e74656e742f75706c6f6164732f323032302f31322f63656c6572792d6172636869746563747572652e6a7067)

## Установка необходимого ПО

### Celery

Для установки `celery` мы можем использовать `pip`:

```pip install celery```

**Celery 4.0+ официально уже не поддерживается для Windows**

Варианты запуска

0. Использовать Linux

1. [Docker](https://habr.com/ru/post/490040/)
2. [WSL 2](https://www.codedisciples.in/celery-windows.html) (для Windows 10)
3. [Переменная окружения](https://www.distributedpython.com/2018/08/21/celery-4-windows/)
   или [прямо в коде](https://github.com/celery/celery/issues/4081#issuecomment-408581158)

### Redis

Установка самого сервиса

```sudo apt install redis-server```

Для линукса,
или [Windows](https://redislabs.com/ebook/appendix-a/a-3-installing-on-windows/a-3-2-installing-redis-on-window/)

Для работы также необходима и библиотека

```pip install redis```

*Все три процесса должны быть запущены одновременно! И Python, который будет отправлять сообщения, и Redis, который 
будет очередью, и Celery worker, который будет выполнять задачи*

## Celery и Python

### Celery и Windows

Если вы используете `Windows` то для того, чтобы все следующие примеры работали, необходимо использовать только
конкретные версии пакетов и версию Python 3.6!

```
python == 3.6
celery == 3.1.25
redis == 2.10.6
```

### Простейший пример

Создадим файл `tasks.py`

Для использования необходимо создать "приложение", в котором необходимо указать название и брокера.

```python
from celery import Celery

broker_url = 'redis://localhost'
app = Celery('tasks', broker=broker_url)


@app.task  # декорирование функции для использования её через Celery 
def add(x, y):
    return x + y
```

Мы не вызывали задачу!!

Для того чтобы мы могли вызвать задачу, необходимо, чтобы у вас были запущены два отдельных приложения, первое Redis
Server:

![](https://djangoalevel.s3.eu-central-1.amazonaws.com/Lesson41/redis-server.png)

Запускаем и оставляем работать!

Celery запускать нужно при запущенном виртуальном окружении!

```
celery -A tasks worker --loglevel=INFO
```

![](https://djangoalevel.s3.eu-central-1.amazonaws.com/Lesson41/celery-run.png)

Также запускаем и не закрываем!

`-A app_name` - имя приложения, `worker` - запустить воркер, `loglevel` - уровень деталей отображаемой информации.

### Запуск и обработка результата

Для запуска задач есть много разных способов, тут рассмотрим базовый.

Открываем консоль:

```python
from tasks import add
add.delay(4, 4)
``` 

Для запуска задачи немедленно используется метод `delay`.

Запуск задач возвращает не результат, а `AsyncResult`, для того чтобы получать значения, необходимо при создании
приложения указать параметр `backend`, который отвечает за то, где будут храниться результаты, таким параметром может 
быть Redis:

```python
broker_url = 'redis://localhost'
app = Celery('tasks', broker=broker_url, backend=broker_url)
```

Обратите внимание, мы используем Redis и в качестве брокера, и в качестве бэкэнда сразу.

Результат будет иметь достаточно большое кол-во методов и атрибутов.

Основные два метода это `ready()` и `get()`:

`ready()` - булево поле, которое отвечает за то, завершилась задача или еще в процессе.

`get()` - ждет выполнения задачи и возвращает результат. Рекомендуется использовать после `ready()`, чтобы не ждать
выполнения впустую.

```python
result = add.delay(4, 4)
result.ready()
True
result.get()
8
```

Иногда описание параметров задачи и ее вызов могут быть в совершенно разных местах, для этого существует механизм
подписи:

```python
s1 = add.s(2, 2)
res = s1.delay()
res.get()
```

В этом примере `s1` - это подпись задачи, то есть задача, заготовленная для выполнения, её можно сериализовать и 
отправить по сети, например, а выполнить в уже совершенно других местах.

Или если вы не знаете параметры целиком:

```python
# incomplete partial: add(?, 2)
s2 = add.s(2)
# resolves the partial: add(8, 2)
res = s2.delay(8)
res.get()
```

Задачи можно группировать:

```python
from celery import group
from proj.tasks import add

group(add.s(i, i) for i in range(10))().get()
```

### Виды запуска

Есть три варианта запуска задач:

```
apply_async(args[, kwargs[, …]])
```

Отправка сообщения с указанием дополнительных параметров:

```
delay(*args, **kwargs)
```

Отправка сообщения без каких-либо параметров самого сообщения:

```
calling (__call__)
```

Просто вызов, декоратор не мешает нам просто вызвать функцию без Celery. :)

### Основные параметры apply_async()

1. `сountdown` - выполнить через определённый промежуток времени

```python
add.apply_async((2, 2), countdown=10)
# выполнить через 10 секунд
```

2. `eta` - выполнить в конкретное время

```python
add.apply_async((2, 2), eta=now() + timedelta(seconds=10))
# выполнить через 10 секунд
```

3. `expires` - время, после которого перестать выполнять задачу, можно указать как цифру, так и время

```python
add.apply_async((4, 5), countdown=60, expires=120)
add.apply_async((4, 5), expires=now() + timedelta(days=2))
```

4. `link` - выполнить другую задачу по завершению текущей, основываясь на результатах текущей

```python
add.apply_async((2, 2), link=add.s(16))
# ( 2 + 2 ) + 16
```

### Периодические задачи

Celery может выполнять какие-либо задачи просто по графику.

Для этого нужно настроить приложение:

```python
app.conf.beat_schedule = {
    'add-every-30-seconds': {
        'task': 'tasks.add',
        'schedule': 30.0,
        'args': (16, 16)
    },
}
app.conf.timezone = 'UTC'

```

Ключ словаря - это только название, можно указать что угодно.

Таск - это выполняемый таск. :)

`args` - его аргументы.

`schedule` - частота выполнения в секундах.

### Выполнение по CRON

```python
from celery.schedules import crontab

app.conf.beat_schedule = {
    # Executes every Monday morning at 7:30 a.m.
    'add-every-monday-morning': {
        'task': 'tasks.add',
        'schedule': crontab(hour=7, minute=30, day_of_week=1),
        'args': (16, 16),
    },
}
```

*Cron* - система задания расписания, можно сделать практически какое угодно.

### По движению солнца

```python
from celery.schedules import solar

app.conf.beat_schedule = {
    # Executes at sunset in Melbourne
    'add-at-melbourne-sunset': {
        'task': 'tasks.add',
        'schedule': solar('sunset', -37.81753, 144.96715),
        'args': (16, 16),
    },
}
```

В данном случае выполнять во время заката по указанным координатам, параметров много, например, закат с учётом зданий ;)

Для запуска по расписанию нужно запускать отдельный воркер для расписания (смотреть в доке)

### Celery и Django

![](https://miro.medium.com/v2/resize:fit:700/1*viyC6TuFLc9JiR6ZlarXWw.jpeg)

Для использования Celery в Django рекомендуется создать еще один файл `celery.py` на одном уровне с `settings.py`

```python
from __future__ import absolute_import

import os

from celery import Celery

# set the default Django settings module for the 'celery' program.
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'djangoProject1.settings')

from django.conf import settings  # noqa

app = Celery('djangoProject1')

# Using a string here means the worker will not have to
# pickle the object when using Windows.
app.config_from_object('django.conf:settings')
app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)
```

`app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)` - эта строчка будет отвечать за автоматический поиск таков во
всех приложениях.

На том же уровне, где и `settings.py` создать\использовать файл `__init__.py` в зависимости от версии Python.

```python
# __init__.py
# This will make sure the app is always imported when
# Django starts so that shared_task will use this app.

from .celery import app as celery_app

__all__ = ('celery_app',)
```

Все задачи необходимо покрывать не стандартным декоратором `task`, а декоратором `shared_task`, тогда Django сможет
автоматически найти все таски в приложении.

```python
# tasks.py

from celery import shared_task
from demoapp.models import Widget


@shared_task
def add(x, y):
    return x + y


@shared_task
def mul(x, y):
    return x * y


@shared_task
def xsum(numbers):
    return sum(numbers)


@shared_task
def count_widgets():
    return Widget.objects.count()


@shared_task
def rename_widget(widget_id, name):
    w = Widget.objects.get(id=widget_id)
    w.name = name
    w.save()
```

Также для Django существует много различных расширений, например:

`django-celery-results` - чтобы хранить результаты в БД или кеше Django, за подробностями в доку.

`django-celery-beat` - настройка для периодических задач, сразу вшитая в админку Django, за подробностями опять же в
доку.


Практика/Домашка:

1. Настроить у себя Celery, чтобы запускались хоть какие-то таски.

2. Сделать кнопку для админа, которая будет подтверждать все возвраты через Celery task.

3. Создать таск, который будет отклонять все возвраты в 6 часов вечера по Киеву.
